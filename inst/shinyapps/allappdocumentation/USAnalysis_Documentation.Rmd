---
title: Uncertainty and Sensitivity Analysis
output:
  html_document:
    theme: null
    highlight: null
    css: ../styles/dsairm.css
    fig_caption: true
    mathjax: default 
    keep_md: false
    includes:
      #in_header: in_header.txt
      before_body: ../styles/dsairm_before_body.txt
      after_body: ../styles/dsairm_after_body.txt 
bibliography: ../media/references.bib
---

##Overview {#shinytab1}
This app allows exploration of the concept of uncertainty and sensitivity analysis. 
For this purpose, we use the basic bacteria infection model introduced in the app of that name. If you haven't done so yet, familiarize yourself and work through that app first.


##The Model {#shinytab2}

###Model Overview
The model is the continous time model in the 'basic bacteria model' app. See the documentation there for the model description. For convenience, here is a quick summary and the equations again.

We model 2 compartments:
* **B** - bacteria 
* **I** - immune response

We specify the following processes/flows: 

1. Bacteria grow/divide at some maximum rate (which we label _g_) and saturate as they approach some maximum carrying capacity, _B~max~_. 
2. Bacteria die at a natural death rate (which we label _d~B~_).
3. Bacteria are killed by the immune response at some rate _k_.
4. The immune response grows proportional to the number of bacteria and itself at some rate _r_.
5. The immune response decays at some rate (which we label _d~I~_).

The equations are given by:

$$\dot B = g B (1-\frac{B}{B_{max}}) - d_B B - k BI$$
$$\dot I = r B I - d_I I$$


###Uncertainty and Sensitivity analysis
To run this model, we need to specify values for the 2 initial conditions, _B~0~_ and _I~0~_, and the 6 model parameters _g_, _B~max~_, _d~B~_, _k_, _r_, _d~I~_. Often, for a given system we want to model, we only have rough estimates for these values. Instead of specifying a fixed value in our model (which results in a single time-series), we can instead specify parameter ranges, choose sets of parameter values from these ranges, and run the model for multiple sets of parameters and record outcomes. The simplest way of specifying parameter ranges is to set an upper and lower bound (based on what we know about the biology of the system) and randomly choose any value within those bounds. We can almost always set bounds even if we know very little about a system. Assume we want to model the death rate of some cell type (e.g. NK cells) in humans. We might not know anything, but we can still be fairly confident that their lifespan is at least 1 second and less than 100 years. That's of course a wide range and we should and usually can narrow ranges further, based on biological knowledge of a given system.

If we are fairly certain that values are close to some quantity, instead of specifying a uniform distribution, we can choose one that is more peaked around the most likely value. Normal distributions are not ideal since they allow negative values, which doesn't make sense for our parameters. The gamma distribution is a better idea, since it leads to only positive values.

In the model here, all parameters are sampled uniformly between the specified upper and lower bound, apart from the bacteria growth rate, which is given by a gamma distribution, with user-specified mean and variance (for this teaching app, there is no biological reason for making bacterial growth different, I just picked one parameter and decided to make it non-uniformly distributed to show you different ways one can implement distributions from which to draw parameter samples.)

The way the samples are drawn could be done completely randomly, but that would lead to inefficient sampling. A smarter method exists, known as Latin Hypercube sampling (LHS). It essentially ensures that we sample the full range of possible parameter combinations in an efficient manner. For more technical details, see [@]. For this app, we use LHS.

Once we specify the ranges for each parameter, the sampling method, and the number of samples, the simulation draws that many samples, runs the model for each sample, and records outcomes of interest. While the underlying simulation returns a time-series for each sample, we are usually not interested in the full time-series. Instead, we are interested in some summary quantity. For instance in this model, we might be interested in the maximum/peak level of bacteria during the infection, the level of bacteria at the end (the steady state) of the infection, and the level of the immune response at steady state. This app records and reports those 3 quantities as _B~peak~_, _B~steady~_ and _I~steady~_.

Results from such simulations for multiple samples can be analyzed in different ways. The most basic one, called *uncertainty analysis* only asks what level of uncertainty we have in our outcomes of interest, given the amount of uncertainty in our model parameter values. This can be graphically represented with a boxplot, and is one of the plot options for this app.

In a next step, we can ask 'how sensitive is the outcome(s) of interest to variation in specific parameters' - that part is the *sensitivity analysis*. When you run the simulations, you essentially do both uncertainty and sensitivity analysis at the same time, it's just a question of how you further process the results. We can graphically insoect the relation between outcome and some parameter with scatterplots. If we find that there is a monotone up or down (or neither) trend between parameter and outcome, we can also summarize the finding using a correlation coefficient. For this type of analysis, using the Spearman rank correlation coefficient is useful, which is what the app produces below the figures.

###A note on randomness in computer simulations
This simulation (as well as some of the others) involves sampling. This leads to some level of randomness. In science, we want to be as reproducible as possible. Fortunately, random numbers on a computer are not completely random, but can be reproduced. In practice, this is done by specifing a random number seed, in essence a starting position for the algorithm to produce pseudo-random numbers. As long as the seed is the same, the code should produce the same pseudo-random numbers each time, thus ensuring reproducibility.


##What to do {#shinytab3}

###Task 1: 
*

###Task 2: 

###Task 3: 


###Task 4: 





##Further Information {#shinytab4}
* This app (and all others) are structured such that the Shiny part (the graphical interface you see and the server-side function that goes with it) calls an underlying R script (or several) which runs the simulation for the model of interest and returns the results.
* For this app, the underlying function running the simulation is called `simulate_introduction.R`. You can call this function directly, without going through the shiny app. Type `?simulate_introduction` into the R console for more information. If you go that route, you need to use the results returned from this function and produce useful output (such as a plot) yourself. 
* You could also modify this R function for your own purposes - though that requires R coding knowledge.
* Some useful books which cover the material of this and most of the other apps (though often a somewhat more mathematical level) are [@vynnycky10] and [@keeling08].

### References


